{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ae8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a895448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_label(temp_x, temp_y):\n",
    "    y_time_list = temp_y['time'].values\n",
    "    y_label = temp_y['label'].values\n",
    "    jdx = 0\n",
    "    label_list = []\n",
    "    for index,row in temp_x.iterrows():\n",
    "        try:\n",
    "            if row['time'] > y_time_list[jdx]:\n",
    "                jdx+=1\n",
    "            label_list.append(y_label[jdx])\n",
    "        except:\n",
    "            label_list.append(y_label[jdx - 1])\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe6614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"TrainingData/\"\n",
    "column_list = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z','subject', 'time', 'label']\n",
    "final_df = pd.DataFrame([], columns = column_list)\n",
    "for i in glob.glob(filepath + '*.csv'):\n",
    "    df_type = i.split('.')[0].split('__')[1]\n",
    "    file_name = i.split('\\\\')[1].split('__')[0]\n",
    "    if df_type == 'x':\n",
    "        x = open(filepath + file_name + '__x.csv')\n",
    "        x = pd.read_csv(x)\n",
    "        x['subject'] = [file_name] * x.shape[0]\n",
    "        \n",
    "        x_time = open(filepath + file_name + '__x_time.csv')\n",
    "        x_time = pd.read_csv(x_time)\n",
    "        x['time'] = x_time\n",
    "        \n",
    "        y = open(filepath + file_name + '__y.csv')\n",
    "        y = pd.read_csv(y)\n",
    "        y['subject'] = [file_name] * y.shape[0]\n",
    "        \n",
    "        y_time = open(filepath + file_name + '__y_time.csv')\n",
    "        y_time = pd.read_csv(y_time)\n",
    "        y['time'] = y_time\n",
    "        \n",
    "        y.columns = ['label', 'subject', 'time']\n",
    "        label_list = upsample_label(x, y)\n",
    "        x['label'] = label_list\n",
    "        x.columns = column_list\n",
    "        final_df = pd.concat([final_df, x], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c180dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1341617, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb47546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>subject</th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.186920</td>\n",
       "      <td>8.344455</td>\n",
       "      <td>2.908057</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>-0.004480</td>\n",
       "      <td>-0.003345</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.544637</td>\n",
       "      <td>8.408659</td>\n",
       "      <td>2.890000</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.022412</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.849308</td>\n",
       "      <td>8.411614</td>\n",
       "      <td>2.900692</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>-0.010670</td>\n",
       "      <td>-0.014223</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.509190</td>\n",
       "      <td>8.118649</td>\n",
       "      <td>2.847298</td>\n",
       "      <td>0.021577</td>\n",
       "      <td>-0.045498</td>\n",
       "      <td>-0.021111</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.226515</td>\n",
       "      <td>8.273807</td>\n",
       "      <td>2.851742</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>-0.016830</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.532063</td>\n",
       "      <td>8.398341</td>\n",
       "      <td>2.856682</td>\n",
       "      <td>0.014484</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>-0.011091</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.433669</td>\n",
       "      <td>8.294719</td>\n",
       "      <td>2.823521</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>-0.029434</td>\n",
       "      <td>-0.008998</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.160676</td>\n",
       "      <td>8.260676</td>\n",
       "      <td>2.827568</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>-0.016748</td>\n",
       "      <td>-0.006027</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.432763</td>\n",
       "      <td>8.272613</td>\n",
       "      <td>2.790050</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.012222</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.511362</td>\n",
       "      <td>8.256774</td>\n",
       "      <td>2.820538</td>\n",
       "      <td>-0.002248</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.011137</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.098018</td>\n",
       "      <td>8.154184</td>\n",
       "      <td>2.901101</td>\n",
       "      <td>-0.010418</td>\n",
       "      <td>-0.042853</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.931769</td>\n",
       "      <td>8.203628</td>\n",
       "      <td>2.958186</td>\n",
       "      <td>-0.015232</td>\n",
       "      <td>-0.006177</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.524325</td>\n",
       "      <td>8.446963</td>\n",
       "      <td>2.874356</td>\n",
       "      <td>-0.003438</td>\n",
       "      <td>0.036310</td>\n",
       "      <td>0.045451</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.615744</td>\n",
       "      <td>8.385348</td>\n",
       "      <td>2.782674</td>\n",
       "      <td>-0.002790</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0.054444</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.392814</td>\n",
       "      <td>8.239121</td>\n",
       "      <td>2.830176</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>0.052817</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.633221</td>\n",
       "      <td>8.197211</td>\n",
       "      <td>2.872404</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>0.039828</td>\n",
       "      <td>0.040343</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.788242</td>\n",
       "      <td>8.201208</td>\n",
       "      <td>2.805275</td>\n",
       "      <td>-0.009608</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>0.025749</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.751849</td>\n",
       "      <td>8.220000</td>\n",
       "      <td>2.847035</td>\n",
       "      <td>-0.012330</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.017562</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.612801</td>\n",
       "      <td>8.290000</td>\n",
       "      <td>2.845603</td>\n",
       "      <td>-0.004444</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.603880</td>\n",
       "      <td>8.246231</td>\n",
       "      <td>2.876940</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>subject_001_01</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z  \\\n",
       "0   4.186920  8.344455  2.908057  0.005771 -0.004480 -0.003345   \n",
       "1   4.544637  8.408659  2.890000  0.007967  0.022412  0.001159   \n",
       "2   4.849308  8.411614  2.900692  0.027778 -0.010670 -0.014223   \n",
       "3   4.509190  8.118649  2.847298  0.021577 -0.045498 -0.021111   \n",
       "4   4.226515  8.273807  2.851742  0.012534  0.000445 -0.016830   \n",
       "5   4.532063  8.398341  2.856682  0.014484  0.028769 -0.011091   \n",
       "6   4.433669  8.294719  2.823521  0.016340 -0.029434 -0.008998   \n",
       "7   4.160676  8.260676  2.827568  0.011222 -0.016748 -0.006027   \n",
       "8   4.432763  8.272613  2.790050 -0.002715  0.023094  0.012222   \n",
       "9   4.511362  8.256774  2.820538 -0.002248  0.001547  0.011137   \n",
       "10  4.098018  8.154184  2.901101 -0.010418 -0.042853  0.005031   \n",
       "11  3.931769  8.203628  2.958186 -0.015232 -0.006177  0.016877   \n",
       "12  4.524325  8.446963  2.874356 -0.003438  0.036310  0.045451   \n",
       "13  4.615744  8.385348  2.782674 -0.002790  0.012677  0.054444   \n",
       "14  4.392814  8.239121  2.830176  0.001527  0.015576  0.052817   \n",
       "15  4.633221  8.197211  2.872404 -0.006495  0.039828  0.040343   \n",
       "16  4.788242  8.201208  2.805275 -0.009608  0.032156  0.025749   \n",
       "17  4.751849  8.220000  2.847035 -0.012330  0.018727  0.017562   \n",
       "18  4.612801  8.290000  2.845603 -0.004444  0.005675  0.003214   \n",
       "19  4.603880  8.246231  2.876940 -0.000502  0.014905  0.001992   \n",
       "\n",
       "           subject   time label  \n",
       "0   subject_001_01  0.025     0  \n",
       "1   subject_001_01  0.050     0  \n",
       "2   subject_001_01  0.075     0  \n",
       "3   subject_001_01  0.100     0  \n",
       "4   subject_001_01  0.125     0  \n",
       "5   subject_001_01  0.150     0  \n",
       "6   subject_001_01  0.175     0  \n",
       "7   subject_001_01  0.200     0  \n",
       "8   subject_001_01  0.225     0  \n",
       "9   subject_001_01  0.250     0  \n",
       "10  subject_001_01  0.275     0  \n",
       "11  subject_001_01  0.300     0  \n",
       "12  subject_001_01  0.325     0  \n",
       "13  subject_001_01  0.350     0  \n",
       "14  subject_001_01  0.375     0  \n",
       "15  subject_001_01  0.400     0  \n",
       "16  subject_001_01  0.425     0  \n",
       "17  subject_001_01  0.450     0  \n",
       "18  subject_001_01  0.475     0  \n",
       "19  subject_001_01  0.500     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacf9aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_label = ['0', '1', '2', '3']\n",
    "y_label = []\n",
    "for i in range(4):\n",
    "    y_label.append(final_df['label'].value_counts()[i])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(x_label, y_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "537e803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_X = final_df[['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n",
    "df_Y = final_df[['label']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "030e6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Dropout, BatchNormalization, MaxPooling1D, UpSampling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf8ae80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.1\n",
    "input_layer = Input([40, 6])\n",
    "\n",
    "conv1 = Conv1D(filters=16, kernel_size=2, padding=\"same\", activation = \"relu\")(input_layer)\n",
    "conv1 = Dropout(dropout_rate)(conv1)\n",
    "conv1 = MaxPooling1D(pool_size =2)(conv1)\n",
    "\n",
    "conv2 = Conv1D(filters=32, kernel_size=2, padding=\"same\", activation = \"relu\")(conv1)\n",
    "conv2 = Dropout(dropout_rate)(conv2)\n",
    "conv2 = MaxPooling1D(pool_size =2)(conv2)\n",
    "\n",
    "conv3 = Conv1D(filters=64, kernel_size=2, padding=\"same\", activation = \"relu\")(conv2)\n",
    "conv3 = Dropout(dropout_rate)(conv3)\n",
    "conv3 = MaxPooling1D(pool_size =2)(conv3)\n",
    "\n",
    "deconv3 = Conv1D(filters=64, kernel_size=2, padding = \"same\", activation=\"relu\")(conv3)\n",
    "deconv3 = Dropout(dropout_rate)(deconv3)\n",
    "deconv3 = UpSampling1D(size =2)(deconv3)\n",
    "\n",
    "deconv2 = Conv1D(filters=32, kernel_size=2, padding = \"same\", activation=\"relu\")(deconv3)\n",
    "deconv2 = Dropout(dropout_rate)(deconv2)\n",
    "deconv2 = UpSampling1D(size =2)(deconv2)\n",
    "\n",
    "deconv1 = Conv1D(filters=16, kernel_size=2, padding = \"same\", activation=\"relu\")(deconv2)\n",
    "deconv1 = Dropout(dropout_rate)(deconv1)\n",
    "deconv1 = UpSampling1D(size =2)(deconv1)\n",
    "\n",
    "output_layer = Conv1D(filters = 4, kernel_size = 2, padding = \"same\", activation=\"softmax\")(deconv1)\n",
    "\n",
    "\n",
    "temp_model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02d8f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(arr, win_size, step_size):\n",
    "    w_list = list()\n",
    "    n_records = arr.shape[0]\n",
    "    remainder = (n_records - win_size) % step_size \n",
    "    num_windows = 1 + int((n_records - win_size - remainder) / step_size)\n",
    "    for k in range(num_windows):\n",
    "        w_list.append(arr[k*step_size:win_size-1+k*step_size+1])\n",
    "    return np.array(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d97571aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# custom weighted loss function (weighted categorical cross entropy)\n",
    "def weighted_crossentropy(y_true, y_pred):\n",
    "    EPSILON = 0.0001\n",
    "\n",
    "    y_t = tf.math.multiply(tf.broadcast_to(tf.constant([2, 1, 1, 2], dtype = float), tf.shape(y_true)) , y_true)\n",
    "    h_t = tf.math.multiply(tf.broadcast_to(tf.constant([1, 1, 1, 1], dtype = float), tf.shape(y_pred)) , y_pred)\n",
    "\n",
    "    return tf.math.reduce_mean(- tf.math.multiply(y_t  , tf.math.log(tf.add(h_t, EPSILON))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a7e5435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1677/1677 [==============================] - 16s 9ms/step - loss: 0.3213 - accuracy: 0.7501\n",
      "Epoch 2/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3174 - accuracy: 0.7505\n",
      "Epoch 3/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3165 - accuracy: 0.7505\n",
      "Epoch 4/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3159 - accuracy: 0.7505\n",
      "Epoch 5/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3153 - accuracy: 0.7506\n",
      "Epoch 6/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3147 - accuracy: 0.7507\n",
      "Epoch 7/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3141 - accuracy: 0.7510\n",
      "Epoch 8/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3136 - accuracy: 0.7512\n",
      "Epoch 9/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3132 - accuracy: 0.7514\n",
      "Epoch 10/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3129 - accuracy: 0.7514\n",
      "Epoch 11/200\n",
      "1677/1677 [==============================] - 15s 9ms/step - loss: 0.3127 - accuracy: 0.7515\n",
      "Epoch 12/200\n",
      " 881/1677 [==============>...............] - ETA: 7s - loss: 0.3126 - accuracy: 0.7514"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-016fbf1041d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m   )\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mtemp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "X_train = make_windows(X_train, 40, 5)\n",
    "y_train = make_windows(y_train, 40, 5)\n",
    "\n",
    "temp_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=weighted_crossentropy,\n",
    "    metrics=[\"accuracy\"],    \n",
    "  )\n",
    "\n",
    "history = temp_model.fit(X_train, y_train, epochs = 200 , batch_size = 128)\n",
    "\n",
    "temp_model.evaluate(X_train, y_train)\n",
    "temp_model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834c33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
